# Natural Language Processing

## Textbook Exercises
Exercises taken from *Speech and Language Processing (3rd ed. draft)* by Dan Jurafsky and James H. Martin. Below are links to my response to the back of book written and programming exercises.

* [Ch 2: Regular Expressions, Text Normalization, Edit Distance](https://github.com/FifthEpoch/NLP/tree/master/WK01/CH02)
* [Ch 3: N-gram Language Models](https://github.com/FifthEpoch/NLP/tree/master/WK01/CH03)
* [Ch 4: Naive Bayes, Text Classification, and Sentiment](https://github.com/FifthEpoch/NLP/tree/master/WK02/CH04)
* [Ch 5: Logistic Regression](https://github.com/FifthEpoch/NLP/tree/master/WK02/CH05)
* [Ch 8: Sequence Labeling for Parts of Speech and Named Entities](https://github.com/FifthEpoch/NLP/tree/master/WK03/CH08)
* [Ch 10: Transformers and Pretrained Language Models](https://github.com/FifthEpoch/NLP/tree/master/WK04/CH10) (WIP)
* [Ch 13: Machine Translation](https://github.com/FifthEpoch/NLP/tree/master/WK04/CH13)
* [Ch 17: Context-Free Grammars and Constituency Parsing](https://github.com/FifthEpoch/NLP/tree/master/WK05/CH17)
* [Ch 23: Word Senses and WordNet](https://github.com/FifthEpoch/NLP/tree/master/WK06/CH23)

## Description of Coursework
This is a laboratory-oriented course on the theory and practice of natural language processing (NLP). Using the popular NLP textbook by Jurafsky and Martin, Speech and Language Processing, we will first gain understanding in the engineering and mathematical foundations of processing sequential text data, concepts and techniques such as basic parsing, Naive Bayes classifier, N-gram, logistic regression. Then, we will cover NLP-specific operations such as tagging, sequence labeling, constituency grammar and parsing, and dependency parsing. In week 5, we will briefly move away from the textbook to learn about Long Short-Term Memory (LSTM) Recurrent Neural Networks (RNN) by reading primary literature on this architecture. After that, we moved to more advanced concepts in NLP such as vector representation of semantics, word senses, lexicon for sentiments, semantic labeling, and information extraction. And finally, we end our study with the very challenging problem of machine translation (MT). We will rely on our textbook as well as primary literature to get a survey of the landscape of MT.

[1] Dan Jurafsky and James H. Martin. Speech and Language Processing 3rd ed. December 2021. [Online PDF](https://web.stanford.edu/~jurafsky/slp3/ed3book_jan122022.pdf) by the authors.

## Research Project
At the end of the quarter, students are expected to complete a final project as the programming assignment for the last 2 weeks of this course. Here is the WIP research proposal by Ting:
* [Research Proposal](https://github.com/FifthEpoch/NLP/tree/master/WK08)
